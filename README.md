# NaturalAPI

_NaturalAPI_ is a REST server (powered by [FastAPI](https://fastapi.tiangolo.com/)) that uses **Agentic CLI tools** ðŸ¤– (Codex, ClaudeCode, GitHub Copilot) to implement server-side logic expressed in **Natural Language**.

# Overview

## Define REST endpoints in Markdown

An endpoint is defined as a _Markdown_ document, here is the source of `chuck-norris.md`:

```Markdown
Tell a Chuck Norris joke.
```

You can get the result of this "logic" at:

```bash
http://localhost:1337/chuck-norris
```

## OpenAPI Documentation

The API surface is build dynamically from the markdown documents you provide, and a OpenAPI compliant API documentation is provided at:

- **data:** http://localhost:1337/openapi.json
- **swagger:** http://localhost:1337/openapi

# Local Development

## Prerequisites
- Python 3.11
- Codex CLI (optional, for AI functionality)

## Installation

1. Clone the repository
```bash
git clone git@github.com:marcopeg/natural-api.git
cd natural-api
```

2. Create and activate virtual environment:
```bash
python3.11 -m venv venv
source venv/bin/activate  # On macOS/Linux
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Start the server:
```bash
# Manual
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

# Makefile
make start
```

5. Test it:
```bash
# Get API info
curl http://localhost:1337/

# Try a dynamic prompt (fallback route)
curl http://localhost:1337/hi

# Try a prompt with path parameters
curl http://localhost:1337/greet/Alice
```

## Dynamic Prompt-Based Routing

The server automatically maps HTTP requests to AI prompts stored in `data/projects/{project}/prompts/*.md`.

### Creating a Prompt

Create a Markdown file in your project's prompts directory (e.g., `data/projects/default/prompts/`):

**Example: `data/projects/default/prompts/greet.md`**
```markdown
---
route: /greet/{name}
verb: GET
model: gpt-5.1-codex-mini
---

Generate a warm, personalized greeting for ${name}. Make it friendly and creative.
```

### Frontmatter Options

```yaml
---
route: /path/{param}    # Optional: Explicit route (supports path parameters)
method: GET             # Optional: HTTP method (default: GET)
model: gpt-5.1-codex    # Optional: LLM model override
agent: codex            # Optional: AI provider override
dry: true               # Optional: Enable dry-run mode for this prompt
body:                   # Optional: Request body schema (POST/PUT/PATCH only)
  field_name:
    type: string        # Types: string, number, integer, boolean
    required: true      # Optional: default is false
    default: "value"    # Optional: default value
    minLength: 3        # Optional: string constraints
    maxLength: 100
    pattern: "^[A-Z]"   # Optional: regex pattern
    enum: [val1, val2]  # Optional: allowed values
    min: 0              # Optional: number constraints
    max: 100
    description: "..."  # Optional: field description
---
```

### Route Matching

The system uses two-tier matching:

1. **Explicit Routes** - Match prompts with `route` configuration
   - `route: /greet/{name}` matches `GET /greet/Alice`
   - Supports path parameters: `{name}`, `{id}`, etc.
   - Supports path wildcards: `{path:path}` (matches entire remaining path)

2. **Fallback Routes** - Match by filename
   - `hi.md` automatically creates `GET /hi`
   - Only matches GET requests
   - Single path segment only (no slashes)

### Variable Substitution

Use bash-style variables in prompt body:

**Syntax:**
- `${variable}` - Simple substitution (empty string if not found)
- `${variable:default}` - Substitution with default value
- `${route.variable}` - Explicit route parameter (from URL path)
- `${body.variable}` - Request body field (from POST/PUT/PATCH JSON)

**Variables come from:**
- Path parameters (e.g., `{name}` in route becomes `${name}` or `${route.name}`)
- Request body fields (e.g., JSON `{"text": "hello"}` becomes `${body.text}`)
- Future: Query parameters (`?role=admin` â†’ `${query.role}`)

**Example with path parameters:**
```markdown
---
route: /user/{username}/profile
---

Create a profile for ${username} with occupation ${occupation:Software Developer}.
```

Request `GET /user/alice/profile` â†’ Prompt: "Create a profile for alice with occupation Software Developer."

**Example with request body:**
```markdown
---
route: /analyze
method: POST
body:
  text:
    type: string
    required: true
  sentiment:
    type: string
    enum: [positive, negative, neutral]
    default: neutral
---

Analyze this text: "${body.text}"
Expected sentiment: ${body.sentiment}
```

Request:
```bash
curl -X POST http://localhost:1337/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "This is amazing!"}'
```

â†’ Prompt: "Analyze this text: \"This is amazing!\"\nExpected sentiment: neutral"

### Example Prompts

The project includes several example prompts in `data/projects/default/prompts/`:

- **`hi.md`** - Simple greeting (fallback route: `GET /hi`)
- **`calc.md`** - Calculator (explicit route: `GET /calculator`)
- **`greet.md`** - Personalized greeting (path param: `GET /greet/{name}`)
- **`analyze.md`** - Text analysis (POST with body validation)

Each project can have its own set of prompts. Create new projects by adding directories under `data/projects/`.

### API Endpoints

**Core Routes:**
- `GET /` - API information and available providers
- `GET /openapi.json?project={id}` - OpenAPI specification for project
- `GET /openapi?project={id}` - Swagger UI for interactive API testing

**Dynamic Routes (prompt-based):**
- Any path matching prompts in `data/projects/{project}/prompts/`
- Controlled by `X-Project-Id` header (default: `default`)
- Controlled by `X-User-Id` header (default: `anonymous`)
- Examples:
  - `GET /hi` - Random greeting (fallback route from `hi.md`)
  - `GET /calculator` - Sum calculation (explicit route from `calc.md`)
  - `GET /greet/Alice` - Personalized greeting with path parameter
  - `POST /analyze/hello` - Text sentiment analysis with request body

**Dry-Run Mode:**
- Add `?dry=true` query parameter or `X-Dry: true` header
- Returns command preview without execution
- CLI clients get markdown, browsers get HTML

### Configuration

Configure the server using environment variables:

```bash
# Select AI provider (default: codex)
export AI_PROVIDER=codex

# Set workspace directory (default: ./data)
export WORKSPACE_DIR=./data

# Set command timeout in seconds (default: 60)
export TIMEOUT_SECONDS=60

# Set logging level (default: INFO)
export LOG_LEVEL=DEBUG

# Enable OpenAPI endpoint (default: true)
export OPENAPI_ENABLED=true
```

### Multi-Project & Multi-User Support

**Project Isolation:**
```bash
# Use specific project
curl http://localhost:1337/hi -H "X-Project-Id: myproject"

# Projects stored in: data/projects/{project-id}/
```

**User Workspaces:**
```bash
# User-specific workspace
curl http://localhost:1337/hi -H "X-User-Id: alice" -H "X-Project-Id: myproject"

# Workspace: data/storage/{user-id}/{project-id}/
```

**Request Logging:**
- All requests logged to: `data/logs/{YYYY}/{MM}/{DD}/YYYYMMDD-HHMM-SSÎ¼Î¼Î¼Î¼Î¼Î¼-{status}.md`
- Includes: request details, AI command, execution output, response
- Format: Structured markdown with all context

### Testing

#### Automated Tests

The project includes comprehensive test coverage:

**1. Unit Tests (fast, mocked dependencies)**
```bash
# Test individual modules
pytest tests/test_prompt_loader.py -v    # Prompt loading & parsing
pytest tests/test_variables.py -v        # Variable substitution
pytest tests/test_router.py -v           # Route matching
pytest tests/test_executor.py -v         # Prompt execution
pytest tests/test_providers.py -v        # AI providers
pytest tests/test_main.py -v             # API endpoints
```

**2. E2E Tests (real server, actual HTTP requests)**
```bash
# Run E2E tests (starts real servers on different ports)
pytest tests/test_e2e.py -v
```

**Run all tests:**
```bash
source venv/bin/activate
pytest tests/ -v
```

**Quick test (skip slow E2E tests):**
```bash
pytest tests/ -v -k "not e2e_hello"
```

#### Manual Testing

With the server running:

```bash
# API info
curl http://localhost:1337/

# Dynamic prompts - fallback routes
curl http://localhost:1337/hi -H "X-Project-Id: default"

# Dynamic prompts - with path parameters
curl http://localhost:1337/greet/Alice -H "X-Project-Id: default"

# Dynamic prompts - POST requests with body
curl -X POST http://localhost:1337/analyze \
  -H "Content-Type: application/json" \
  -H "X-Project-Id: default" \
  -d '{"text": "This is amazing!"}'

# Dry-run mode (preview command)
curl "http://localhost:1337/hi?dry=true" -H "X-Project-Id: default"

# OpenAPI/Swagger UI
open http://localhost:1337/openapi?project=default

# Multi-project
curl http://localhost:1337/hi -H "X-Project-Id: test"

# Multi-user
curl http://localhost:1337/hi -H "X-User-Id: alice" -H "X-Project-Id: default"

# Check logs
ls -lh data/logs/$(date +%Y/%m/%d)/
```

## Development Workflow

```bash
# 1. Activate virtual environment
source venv/bin/activate

# 2. Start server with auto-reload
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

# 3. In another terminal, run tests
source venv/bin/activate
pytest tests/ -v
```

## Configuration

Configure the server using environment variables:

```bash
# Select AI provider (default: codex)
export AI_PROVIDER=codex

# Set workspace directory (default: ./data)
export WORKSPACE_DIR=./data

# Set command timeout in seconds (default: 60)
export TIMEOUT_SECONDS=60
```

## Architecture

### Provider System

```
AIProvider (Abstract Base Class)
â”œâ”€â”€ CodexProvider (Codex CLI)
â”œâ”€â”€ ClaudeProvider (Future)
â””â”€â”€ CopilotProvider (Future)
```

**Current Providers:**
- `codex` - Wraps Codex CLI (`codex exec` commands)

**Configuration-driven:** Set `AI_PROVIDER` environment variable to switch providers.

### Prompt Routing System

```
HTTP Request
    â†“
DynamicRouter (load prompts from data/prompts/*.md)
    â†“
RouteMatch (explicit route or fallback filename)
    â†“
PromptExecutor (substitute variables, execute AI)
    â†“
AIProviderResult (return raw output)
```

**Key Components:**
- **PromptLoader** - Parses Markdown files with YAML frontmatter
- **DynamicRouter** - Matches requests to prompts (explicit then fallback)
- **VariableSubstitution** - Replaces `${var}` with path parameters
- **PromptExecutor** - Runs AI provider with processed prompt

### Error Handling

Comprehensive HTTP status codes:
- `200` - Success
- `404` - Not Found (no matching prompt)
- `408` - Request Timeout (AI command exceeded timeout)
- `500` - Internal Server Error (AI command failed)
- `503` - Service Unavailable (AI provider not configured/installed)

All errors return JSON with details:
```json
{
  "detail": {
    "error": "Error type",
    "message": "Detailed message",
    "provider": "codex"
  }
}
```

## Project Structure

```
natural-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # FastAPI application with dynamic routing
â”‚   â”œâ”€â”€ config.py            # Configuration management (multi-project/user)
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ loader.py        # Prompt file loading & parsing
â”‚   â”‚   â”œâ”€â”€ router.py        # Dynamic route matching
â”‚   â”‚   â”œâ”€â”€ variables.py     # Variable substitution
â”‚   â”‚   â”œâ”€â”€ executor.py      # Prompt execution with AI
â”‚   â”‚   â””â”€â”€ body_validator.py # Request body schema validation
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ base.py          # AIProvider abstract base class
â”‚   â”‚   â”œâ”€â”€ codex.py         # CodexProvider implementation
â”‚   â”‚   â””â”€â”€ factory.py       # ProviderFactory
â”‚   â”œâ”€â”€ logging/
â”‚   â”‚   â”œâ”€â”€ models.py        # LogEntry dataclass
â”‚   â”‚   â”œâ”€â”€ timestamp.py     # Timestamp utilities
â”‚   â”‚   â”œâ”€â”€ formatter.py     # Markdown log formatter
â”‚   â”‚   â”œâ”€â”€ html_formatter.py # HTML formatter for browsers
â”‚   â”‚   â”œâ”€â”€ writer.py        # Log file writer
â”‚   â”‚   â””â”€â”€ context.py       # Request logging context
â”‚   â””â”€â”€ openapi/
â”‚       â””â”€â”€ generator.py     # OpenAPI spec generation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_main.py         # API endpoint tests
â”‚   â”œâ”€â”€ test_config.py       # Config tests (projects/users)
â”‚   â”œâ”€â”€ test_prompt_loader.py # Prompt loading tests
â”‚   â”œâ”€â”€ test_variables.py    # Variable substitution tests
â”‚   â”œâ”€â”€ test_router.py       # Route matching tests
â”‚   â”œâ”€â”€ test_executor.py     # Prompt execution tests
â”‚   â”œâ”€â”€ test_providers.py    # Provider tests
â”‚   â”œâ”€â”€ test_body_validator.py # Request body validation tests
â”‚   â”œâ”€â”€ test_logging_*.py    # Logging system tests (27 tests)
â”‚   â”œâ”€â”€ test_openapi_*.py    # OpenAPI tests
â”‚   â”œâ”€â”€ test_e2e.py          # E2E tests (real server)
â”‚   â””â”€â”€ e2e_utils.py         # E2E utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ projects/            # Multi-project support
â”‚   â”‚   â”œâ”€â”€ default/
â”‚   â”‚   â”‚   â”œâ”€â”€ AGENTS.md    # Project-level AI instructions
â”‚   â”‚   â”‚   â””â”€â”€ prompts/     # Project-specific prompts
â”‚   â”‚   â”‚       â”œâ”€â”€ hi.md
â”‚   â”‚   â”‚       â”œâ”€â”€ calc.md
â”‚   â”‚   â”‚       â”œâ”€â”€ greet.md
â”‚   â”‚   â”‚       â””â”€â”€ analyze.md
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚       â””â”€â”€ prompts/
â”‚   â”œâ”€â”€ storage/             # User workspaces per project
â”‚   â”‚   â”œâ”€â”€ anonymous/
â”‚   â”‚   â”‚   â””â”€â”€ default/     # User workspace
â”‚   â”‚   â””â”€â”€ alice/
â”‚   â”‚       â””â”€â”€ myproject/
â”‚   â””â”€â”€ logs/                # Request logs
â”‚       â””â”€â”€ {YYYY}/{MM}/{DD}/
â”‚           â””â”€â”€ YYYYMMDD-HHMM-SSÎ¼Î¼Î¼Î¼Î¼Î¼-{status}.md
â””â”€â”€ requirements.txt         # Python dependencies
```

## License

MIT
